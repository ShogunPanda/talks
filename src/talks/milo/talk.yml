---
config: common.config
document:
  title: Milo, a new HTTP parser for Node.js
  titleFormatted: |
    Milo, a new HTTP parser for Node.js
  author: common.author
  company: common.company
slides:
  - layout: cover
  - layout: separator
    title: Being reckless (sometimes) pays off!
    image: '@talk/ski.webp'
    classes:
      slide: bg-nf-neon-blue
  - layout: hello
  - layout: nearform
  - layout: separator
    title: We all love HTTP!
    image: '@talk/love.webp'
    classes:
      slide: bg-nf-brunch-pink
  - layout: separator
    title: Which HTTP are you?
    image: '@talk/palette.webp'
    classes:
      slide: bg-nf-orange-split
  - title: The choice is narrow
    content: Even if HTTP is almost 25 years old, only 3 current versions of it exists as of today.
    items:
      - index: 1
        title: HTTP/1.1
        text: The last version of the initial protocol. By far the most famous and most used.
      - index: 2
        title: HTTP/2
        text: Developed on top of SPDY to remove some problems of HTTP.
      - index: 3
        title: HTTP/3
        text: Developed on top of QUIC to solve TCP problems.
  - title: What about Node.js?
    items:
      - index: 1+2
        title: HTTP/1.1 and HTTP/2
        text: Node.js has a stable implementation.
      - index: 3
        title: HTTP/3
        text: Work in progress, *stay tuned!*
    options:
      horizontal: true
  - layout: separator
    title: Let's focus!
    image: '@talk/focus.webp'
    classes:
      slide: bg-nf-midnight-blue
  - layout: side
    title: The current parser
    content:
      - '**llhttp** is the current HTTP parser.'
      - Written by Fedor Indutny in 2019, is the default since Node.js 12.
    image: '@talk/llhttp.webp'
  - layout: side
    title: How it works?
    content:
      - 'llhttp is a state based HTTP parser based on llparse.'
      - llparse is capable to generate a very performant C code out of a TypeScript description of the possible states.
    image: '@talk/llhttp_states.webp'
  - title: "llhttp: what's wrong with it?"
    items:
      - icon: 'bug'
        title: Hard to debug and release
        text: The transpilation makes hard to debug issues.
      - icon: 'history'
        title: Backward compatibility
        text: Supporting different versions of HTTP (included obsoleted) introduces unneeded complexity.
      - icon: 'heart-handshake'
        title: You give them a finger, they take the arm
        text: Leniency-prone approach opens the door for a lot of edge cases and vulnerabilities opportunities.
  - layout: separator
    title: Do we have the solution?
    image: '@talk/solution.webp'
    classes:
      slide: bg-nf-brunch-pink
  - layout: separator
    title: Yes, start fresh!
    image: '@talk/fresh.webp'
    classes:
      slide: bg-nf-orange-split
  - layout: separator
    title: Say hello to Milo!
    image: '@talk/milo.webp'
    classes:
      slide: bg-nf-brunch-pink
  - layout: side
    title: Let's drop the bomb!
    items:
      - icon: 'source-code'
        title: Milo is written in Rust
        text: The language has proven flexible and performant to achieve the task.
      - icon: 'history'
        title: I did not know it before Milo
        text: I purposely choose Rust to see how hard is to embrace for a new prospect contributor.
      - icon: 'heart'
        title: Be cool
        text: "I don't want to start another language flame. *Please.* ❤️"
    image: '@talk/rust-logo.webp'
  - title: Do not throw the goods away
    items:
      - icon: 'heart'
        title: llhttp is a piece of art
        text: It deeply inspires Milo and I kept most of his architecture. *Kudos to Fedor!*
      - icon: 'status-change'
        title: Still a state machine, but simpler
        text: llhttp has **80** possible states, Milo only *32*.
      - icon: 'git-branch'
        title: Declarative, reinvented
        text: Rust enables to declare states with no code restriction.
  - layout: separator
    title: How is that possible?
    image: '@talk/dog.webp'
    classes:
      slide: bg-nf-midnight-blue
  - layout: separator
    title: It's all in the macros!
    image: '@talk/macro.webp'
    classes:
      slide: bg-nf-orange-split
  - title: Rust macro system is insanely powerful
    items:
      - icon: 'plug-connected'
        title: It is evaluated at compile time
        text: The executed code is inherently optimized.
      - icon: 'brain'
        title: No code limitation
        text: As long as you return valid Rust code, everything is permitted.
      - icon: 'bug'
        title: Easily debuggable
        text: Via [*cargo-expand*](https://github.com/dtolnay/cargo-expand), it's easy to see what is the final compiled code.
  - title: Examples are worth more than 1000 words
    items:
      - code:
          language: rust
          content: |
            state!(chunk_end, {
              match data {
                crlf!() => {
                  parser.chunk_size = 0;
                  parser.remaining_chunk_size = 0;
                  move_to!(chunk_length, 2)
                }
                otherwise!(2) => fail!(
                  UNEXPECTED_CHARACTER, 
                  "Unexpected character after chunk data"
                ),
                _ => suspend!(),
              }
            });
        classes:
          item: flex-initial
          code: w-auto h-auto mb-0 narrow text-left
      - image: '@talk/arrow-right.webp'
        classes:
          item: flex-initial
          image: w-auto h-auto min-w-auto min-h-auto h-0_5sp mx-4ch mb-0
      - code:
          language: rust
          content: |
            #[inline(always)]
            fn state_chunk_end(parser: &mut Parser, data: &[c_uchar]) -> isize {
                let mut data = data;
                match data {
                    [b'\r', b'\n', ..] => {
                        parser.chunk_size = 0;
                        parser.remaining_chunk_size = 0;
                        parser.move_to(State::CHUNK_LENGTH, (2) as isize)
                    }
                    [_u0, _u1, ..] => {
                        parser.fail_str(
                          Error::UNEXPECTED_CHARACTER,
                          "Unexpected character after chunk data",
                        )
                    }
                    _ => SUSPEND,
                }
            }
        classes:
          item: flex-initial
          code: w-auto h-auto mb-0 text-left
    classes:
      items: flex flex-1 gap-x-0sp font-size-0_8em items-center
    options:
      horizontal: true
      skipSpacer: true
      skipDefaultClasses: true
      noGap: true
  - layout: separator
    title: What about resources?
    image: '@talk/piggy-bank.webp'
    classes:
      slide: bg-nf-midnight-blue
  - title: Milo has very small memory footprint
    items:
      - icon: 'rocket'
        title: (Almost) No copy eager parsing
        text: Data is analyzed in place without copying it.
      - icon: 'link'
        title: Only one exception (optional)
        text: When parsing, only the unconsumed part of the input is copied in the parser.
      - icon: 'heart'
        title: Convenience at your service
        text: Milo manages unconsumed data for you, making your life easier.
  - layout: separator
    title: Strict, period.
    image: '@talk/wall.webp'
    classes:
      slide: bg-nf-darkest-blue
  - layout: image
    title: Let's see it in action!
    image: '@talk/action.webp'
  - title: Sample code (Rust)
    code:
      language: rust
      content: |
        use std::os::raw::c_uchar;
        use std::{slice, str};

        use milo::Parser;

        fn log(what: &str, p: &Parser, data: *const c_uchar, size: usize) -> isize {
          let contents = unsafe { str::from_utf8_unchecked(slice::from_raw_parts(data, size)) };
          println!("Pos={} {}: {}", p.position.get(), what, contents);
          0
        }

        fn main() {
          let parser = Parser::new();
          let message = "HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\nabc";

          parser.callbacks.on_status.set(|p, data, size| log("Status", p, data, size));
          parser.callbacks.on_header_name.set(|p, data, size| log("Header name", p, data, size));
          parser.callbacks.on_header_value.set(|p, data, size| log("Header value", p, data, size));
          parser.callbacks.on_data.set(|p, data, size| log("Body", p, data, size));

          parser.parse(message.as_ptr(), message.len());
        }
  - title: Output (Rust)
    code:
      language: console
      content: |
        shogun@panda:~$ cargo run
        Pos=9 Status: 200
        Pos=17 Header name: Content-Length
        Pos=33 Header value: 3
        Pos=38 Body: abc
  - layout: separator
    title: But Node.js uses C++!
    image: '@talk/incompatible.webp'
    classes:
      slide: bg-nf-brunch-pink
  - layout: side
    title: The C++ workflow
    image: '@talk/cbindgen.webp'
    items:
      - icon: 'puzzle-2'
        title: 'A tool generates the headers'
        text: '[*cbindgen*](https://github.com/mozilla/cbindgen) generates a fully working C or C++ header file. Only a small TOML file is needed.'
      - icon: 'link'
        title: Cargo generates a static library
        text: Rust supports this out of the box. The generated *libmilo.a* file can be statically linked in any C/C++ executable.
  - title: Sample code (C++)
    code:
      language: rust
      content: |
        #include "milo.h"
        #include "stdio.h"
        #include "string.h"

        typedef unsigned char uchar_t;

        int main() {
          milo::Parser* parser = milo::milo_create();
          const char* message = "HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\nabc";

          parser->callbacks.on_data = [](const milo::Parser* p, const uchar_t* data, uintptr_t size) -> intptr_t {
            uchar_t* content = reinterpret_cast<uchar_t*>(malloc(sizeof(uchar_t) * size));
            strncpy(reinterpret_cast<char*>(content), reinterpret_cast<const char*>(data), size);

            printf("Pos=%llu Body: %s\n", p->position, content);
            free(content);
            return 0;
          };

          milo::milo_parse(parser, reinterpret_cast<const uchar_t*>(message), strlen(message));
        }
  - title: Output (C++)
    code:
      language: console
      content: |
        shogun@panda:~$ clang++ -std=c++11 -o example libmilo.a main.cc
        shogun@panda:~$ ./example
        Pos=38 Body: abc
  - layout: separator
    title: But I want to support SmartOS!
    image: '@talk/incompatible.webp'
    classes:
      slide: bg-nf-brunch-pink
  - layout: side
    title: WASM will save us!
    image: '@talk/wasm-bindgen.webp'
    items:
      - icon: 'puzzle-2'
        title: 'WebAssembly is fully supported'
        text: 'Rust has always considered WebAssembly a first class citizen.'
      - icon: 'link'
        title: The toolchain makes it easy
        text: '[*wasm-bindgen*](https://github.com/rustwasm/wasm-bindgen) generates a fully working JS module which internally loads a WASM file.'
  - title: Sample code (Node.js with WebAssembly)
    code:
      language: javascript
      content: |
        import milo from 'milo'

        const message = Buffer.from('HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\nabc')

        const buffer = milo.__wasm.__wbindgen_malloc(4096, 1) >>> 0

        const parser = new milo.Parser()

        parser.setOnData((at, len) => {
          console.log(`Pos=${Number(parser.position)} Body: ${message.slice(at, at + len).toString()}`)
          return 0
        })

        new Uint8Array(milo.__wasm.memory.buffer, buffer, 4096).set(message)
        parser.parse(buffer, message.length)
  - title: Output (Node.js with WebAssembly)
    code:
      language: console
      content: |
        shogun@panda:~$ node index.mjs
        Pos=38 Body: abc
  - layout: image
    title: And that's Milo!
    image: '@talk/safe.webp'
  - title: Performance in Node (native, preliminary)
    items:
      - code:
          language: console
          content: |
            ======================================== llhttp ====================================

            ┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
            │ Stat    │ 2.5% │ 50%  │ 97.5% │ 99%  │ Avg     │ Stdev   │ Max   │
            ├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
            │ Latency │ 0 ms │ 0 ms │ 0 ms  │ 0 ms │ 0.01 ms │ 0.12 ms │ 17 ms │
            └─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
            ┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
            │ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg     │ Stdev   │ Min     │
            ├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
            │ Req/Sec   │ 25119   │ 25119   │ 29055   │ 30447   │ 28808   │ 1411.49 │ 25114   │
            ├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
            │ Bytes/Sec │ 2.11 MB │ 2.11 MB │ 2.44 MB │ 2.56 MB │ 2.42 MB │ 118 kB  │ 2.11 MB │
            └───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘

            Req/Bytes counts sampled once per second.
            # of samples: 11

            317k requests in 11.02s, 26.6 MB read
        classes:
          item: flex
          code: w-auto h-auto mb-0 narrow text-left font-size-0_8em
      - code:
          language: console
          content: |
            ========================================  milo  ====================================

            ┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
            │ Stat    │ 2.5% │ 50%  │ 97.5% │ 99%  │ Avg     │ Stdev   │ Max   │
            ├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
            │ Latency │ 0 ms │ 0 ms │ 0 ms  │ 0 ms │ 0.01 ms │ 0.11 ms │ 17 ms │
            └─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
            ┌───────────┬────────┬────────┬─────────┬─────────┬─────────┬────────┬─────────┐
            │ Stat      │ 1%     │ 2.5%   │ 50%     │ 97.5%   │ Avg     │ Stdev  │ Min     │
            ├───────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┤
            │ Req/Sec   │ 28511  │ 28511  │ 30287   │ 33407   │ 30765.1 │ 1458.2 │ 28507   │
            ├───────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┤
            │ Bytes/Sec │ 2.4 MB │ 2.4 MB │ 2.55 MB │ 2.81 MB │ 2.58 MB │ 122 kB │ 2.39 MB │
            └───────────┴────────┴────────┴─────────┴─────────┴─────────┴────────┴─────────┘

            Req/Bytes counts sampled once per second.
            # of samples: 11

            338k requests in 11.02s, 28.4 MB read
        classes:
          item: flex
          code: w-auto h-auto mb-0 narrow text-left font-size-0_8em
    classes:
      items: flex flex-1 gap-x-2ch font-size-0_8em items-center
    options:
      horizontal: true
      skipSpacer: true
      skipDefaultClasses: true
      noGap: true
  - title: What's missing?
    items:
      - icon: 'puzzle-2'
        title: Node.js integration
        text: I just finished integrating the WebAssembly version in undici. Our beloved runtime is next.
      - icon: 'rocket'
        title: SIMD in WebAssembly
        text: Milo matches or outperforms llhttp in native mode, but it is slower when compiled in WebAssembly.
      - icon: 'checks'
        title: Migrate llhttp test suite
        text: The llhttp test suite (originally from http_parser) is crucial to ensure correctness of the parser.
    options:
      horizontal: true
  - layout: quote
    sentence: A person who never made a mistake never tried anything new.
    author: Albert Einstein
  - layout: end
