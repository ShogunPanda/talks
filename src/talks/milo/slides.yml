---
layout: cover
# ---

---
layout: nearform
# ---

---
layout: separator
title: |
  Being reckless
  (sometimes) 
  pays off!
image:
  url: '@talk/ski.webp'
options:
  background: blue
  foreground: white
decorations:
  logo: black

---
layout: hello
# ---

---
layout: separator
title: We all love HTTP!
image:
  url: '@talk/love.webp'
options:
  background: pink
  foreground: white
decorations:
  logo: black

---
layout: separator
title: |
  Which HTTP
  are you?
image:
  url: '@talk/palette.webp'
options:
  background: green
  foreground: white

---
title: The choice is narrow
content:
  - Even if the HTTP protocol is more than 30 years old, only *three* current versions of it exist as of today. The others are considered obsolete.
items:
  entries:
    - index: 1
      title: HTTP/1.1
      text: The last version of the initial protocol. By far the most famous and most used.
    - index: 2
      title: HTTP/2
      text: Developed on top of SPDY to remove some problems of HTTP.
    - index: 3
      title: HTTP/3
      text: Developed on top of QUIC to solve TCP problems.

---
title: What about Node.js?
items:
  entries:
    - index: 1+2
      title: HTTP/1.1 and HTTP/2
      text: Node.js has a stable implementation.
    - index: 3
      title: HTTP/3
      text: Work in progress, *stay tuned!*
  horizontal: true

---
layout: separator
title: Let's focus!
image:
  url: '@talk/focus.webp'
options:
  background: blue
  foreground: white

---
layout: side
title: The current parser
content:
  - '**llhttp** is the current HTTP parser.'
  - Written by Fedor Indutny in 2019, is the default since Node.js 12.
image:
  url: '@talk/llhttp.webp'

---
layout: side
title: How it works?
content:
  - llhttp is a state based HTTP parser based on llparse.
  - llparse is capable to generate a very performant C code out of a TypeScript description of the possible states.
image:
  url: '@talk/llhttp_states.webp'

---
title: "llhttp: what's wrong with it?"
items:
  entries:
    - icon: bug
      title: Hard to debug and release
      text: The transpilation makes hard to debug issues.
    - icon: history
      title: Backward compatibility
      text: Supporting obsolete versions of HTTP introduces unneeded complexity.
    - icon: handshake
      title: You give them a finger, they take the arm
      text: Leniency-prone approach opens the door for edge cases and vulnerabilities opportunities.

---
layout: separator
title: Do we have the solution?
image:
  url: '@talk/solution.webp'
options:
  background: fuchsia
  foreground: white

---
layout: separator
title: Yes, start fresh!
image:
  url: '@talk/fresh.webp'
options:
  background: green
  foreground: white

---
layout: separator
title: Say hello to <span class="theme@fg-black">Milo</span>!
image:
  url: '@talk/milo.webp'
options:
  background: pink
  foreground: white
decorations:
  logo: black
  permalink: white

---
layout: side
title: Let's drop the bomb!
items:
  entries:
    - icon: code
      title: Milo is written in Rust
      text: The language has proven flexible and performant to achieve the task.
    - icon: history
      title: I did not know it before Milo
      text: I purposely made the choice to see how hard it is for a new prospect contributor.
    - icon: heart
      title: Be cool
      text: I don't want to start another language flame. *Please.* ❤️
image:
  url: '@talk/rust-logo.webp'

---
title: Do not throw the goods away
items:
  entries:
    - icon: heart
      title: llhttp is a piece of art
      text: It deeply inspires Milo and I kept most of his architecture. *Kudos to Fedor!*
    - icon: diagram-project
      title: Still a state machine, but simpler
      text: llhttp has **80** possible states, Milo only *32*.
    - icon: code-branch
      title: Declarative, reinvented
      text: Rust enables to declare states with no code restriction.

---
layout: separator
title: How is that possible?
image:
  url: '@talk/dog.webp'
options:
  background: blue
  foreground: white

---
layout: separator
title: It's all in the macros!
image:
  url: '@talk/macro.webp'
options:
  background: green
  foreground: white

---
title: Rust macro system is insanely powerful
items:
  entries:
    - icon: gear-complex-code
      title: It is evaluated at compile time
      text: The executed code is inherently optimized.
    - icon: brain
      title: No code limitation
      text: As long as you return valid Rust code, everything is permitted.
    - icon: bug
      title: Easily debuggable
      text: Via [*cargo-expand*](https://github.com/dtolnay/cargo-expand), it's easy to see what is the final compiled code.

---
title: Examples are worth more than 1000 words
items:
  entries:
    - code:
        language: rust
        content: |
          state!(request_protocol, {
            match data {
              string!("HTTP/") | string!("RTSP/") => {
                callback!(on_protocol, 4);
                parser.position += 4;

                move_to!(request_version, 1)
              }
              otherwise!(5) => 
                fail!(UNEXPECTED_CHARACTER, "Expected protocol"),
              _ => suspend!(),
            }
          });
      className:
        root: talk@example__from
    - image: '@talk/arrow-right.webp'
      className:
        root: talk@example__arrow
        image: talk@example__arrow__image
    - code:
        language: rust
        content: |
          #[inline(always)]
          pub fn state_request_protocol(
            parser: &mut Parser, data: &[c_uchar],
          ) -> usize {
              let mut data = data;
              match data {
                  [72u8, 84u8, 84u8, 80u8, 47u8, ..] | 
                  [82u8, 84u8, 83u8, 80u8, 47u8, ..] => {
                      #[cfg(not(target_family = "wasm"))]
                      {
                          (parser.callbacks.on_protocol)(
                            parser, parser.position, 4,
                          );
                      };
                      parser.position += 4;
                      parser.move_to(STATE_REQUEST_VERSION, 1)
                  }
                  [_u0, _u1, _u2, _u3, _u4, ..] => {
                      parser.fail(
                        ERROR_UNEXPECTED_CHARACTER, 
                        "Expected protocol",
                      )
                  }
                  _ => SUSPEND,
              }
          }
      className:
        root: talk@example__to
  className: talk@example
  horizontal: true
  spacer: false
  gap: false
  defaultclassName: false

---
layout: separator
title: What about resources?
image:
  url: '@talk/piggy-bank.webp'
options:
  background: amber
decorations:
  logo: black

---
title: Milo has very small memory footprint
items:
  entries:
    - icon: rocket
      title: (Almost) No copy eager parsing
      text: Data is analyzed in place without copying it.
    - icon: link
      title: Only one exception (optional)
      text: When parsing, only the unconsumed part of the input is copied in the parser.
    - icon: heart
      title: Convenience at your service
      text: Milo manages unconsumed data for you, making your life easier.

---
layout: separator
title: Strict, period!
image:
  url: '@talk/wall.webp'
options:
  background: red
  foreground: white

---
layout: image
title: Let's see it in action!
image:
  url: '@talk/action.webp'

---
title: Sample code (Rust)
code:
  language: rust
  content: |
    use core::ffi::c_void;
    use core::slice;
    use milo::Parser;

    fn main() {
      // Create the parser.
      let mut parser = Parser::new();

      // Prepare a message to parse.
      let message = String::from("HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\nabc");
      parser.context = message.as_ptr() as *mut c_void;

      // Milo works using callbacks, All callbacks have the same signature.
      parser.callbacks.on_data = |p: &mut Parser, from: usize, size: usize| {
        let message = unsafe { 
          std::str::from_utf8_unchecked(slice::from_raw_parts(p.context.add(from) as *const u8, size)) 
        };

        // Do something with the informations.
        println!("Pos={} Body: {}", p.position, message);
      };

      // Now perform the main parsing using milo.parse.
      parser.parse(message.as_ptr(), message.len());
    }
  className:
    root: talk@code

---
title: Output (Rust)
code:
  language: output
  content: |
    shogun@panda:~/example$ cargo run
    Pos=38 Body: abc

---
layout: separator
title: |
  But Node.js
  uses C++!
image:
  url: '@talk/incompatible.webp'
options:
  background: green
  foreground: white
decorations:
  logo: black

---
layout: side
title: The C++ workflow
image:
  url: '@talk/cbindgen.webp'
items:
  entries:
    - icon: gear-complex-code
      title: A tool generates the headers
      text: '[*cbindgen*](https://github.com/mozilla/cbindgen) generates a fully working C or C++ header file. Only a small TOML file is needed.'
    - icon: link
      title: Cargo generates a static library
      text: The generated *libmilo.a* file can be statically linked in any C/C++ executable.

---
title: Sample code (C++)
code:
  # TODO@PI: Why is C++ Highlighting not working?
  language: rust
  content: |
    #include "milo.h"
    #include "stdio.h"
    #include "string.h"

    int main() {
      // Create the parser.
      milo::Parser* parser = milo::milo_create();

      // Prepare a message to parse.
      const char* message = "HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\nabc";
      parser->context = (char*) message;

      // Milo works using callbacks, All callbacks have the same signature.
      parser->callbacks.on_data = [](milo::Parser* p, uintptr_t from, uintptr_t size) {
        char* payload = reinterpret_cast<char*>(malloc(sizeof(char) * size));
        strncpy(payload, reinterpret_cast<const char*>(p->context) + from, size);
        printf("Pos=%lu Body: %s\n", p->position, payload);
        free(payload);
      };

      // Now perform the main parsing using milo.parse. The method returns the number of consumed characters.
      milo::milo_parse(parser, reinterpret_cast<const unsigned char*>(message), strlen(message));

      // Cleanup used resources.
      milo::milo_destroy(parser);
    }
  className:
    root: talk@code

---
title: Output (C++)
code:
  language: output
  content: |
    shogun@panda:~/example$ clang++ -std=c++11 -o example libmilo.a main.cc
    shogun@panda:~/example$ ./example
    Pos=38 Body: abc

---
layout: separator
title: |
  But I want
  to support
  SmartOS!
image:
  url: '@talk/incompatible.webp'
options:
  background: fuchsia
  foreground: white

---
layout: side
title: WASM will save us!
image:
  url: '@talk/wasm-bindgen.webp'
items:
  entries:
    - icon: gear-complex-code
      title: WebAssembly is fully supported
      text: Rust has always considered WebAssembly a first class citizen.
    - icon: link
      title: The toolchain makes it easy
      text: '[*wasm-bindgen*](https://github.com/rustwasm/wasm-bindgen) generates a fully working JS module which internally loads a WASM file.'

---
title: Sample code (Node.js with WebAssembly)
code:
  language: javascript
  content: |
    import { milo } from ''@perseveranza-pets/milo''

    // Prepare a message to parse.
    const message = Buffer.from('HTTP/1.1 200 OK\r\nContent-Length: 3\r\n\r\nabc')

    // Allocate a memory in the WebAssembly space. This speeds up data copying to the WebAssembly layer.
    const ptr = milo.alloc(message.length)

    // Create a buffer we can use normally.
    const buffer = Buffer.from(milo.memory.buffer, ptr, message.length)

    // Create the parser.
    const parser = milo.create()

    // Milo works using callbacks, All callbacks have the same signature.
    milo.setOnData(parser, (p, from, size) => {
      console.log(`Pos=${milo.getPosition(p)} Body: ${message.slice(from, from + size).toString()}`)
    })

    // Now perform the main parsing using milo.parse. The method returns the number of consumed characters.
    buffer.set(Buffer.from(message), 0)
    const consumed = milo.parse(parser, ptr, message.length)

    // Cleanup used resources.
    milo.destroy(parser)
    milo.dealloc(ptr, message.length)
  className:
    root: talk@code

---
title: Output (Node.js with WebAssembly)
code:
  language: output
  content: |
    shogun@panda:~/example$ node index.mjs
    Pos=38 Body: abc

---
layout: image
title: And that's Milo!
image:
  url: '@talk/safe.webp'

---
title: Performance in Node (native, preliminary)
items:
  entries:
    - code:
        language: none
        content: |
          ======================================== llhttp ====================================

          ┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
          │ Stat    │ 2.5% │ 50%  │ 97.5% │ 99%  │ Avg     │ Stdev   │ Max   │
          ├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
          │ Latency │ 0 ms │ 0 ms │ 0 ms  │ 0 ms │ 0.01 ms │ 0.12 ms │ 17 ms │
          └─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
          ┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
          │ Stat      │ 1%      │ 2.5%    │ 50%     │ 97.5%   │ Avg     │ Stdev   │ Min     │
          ├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
          │ Req/Sec   │ 25119   │ 25119   │ 29055   │ 30447   │ 28808   │ 1411.49 │ 25114   │
          ├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
          │ Bytes/Sec │ 2.11 MB │ 2.11 MB │ 2.44 MB │ 2.56 MB │ 2.42 MB │ 118 kB  │ 2.11 MB │
          └───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘

          Req/Bytes counts sampled once per second.
          # of samples: 11

          317k requests in 11.02s, 26.6 MB read
      className:
        root: talk@performance__result
    - code:
        language: none
        content: |
          ========================================  milo  ====================================

          ┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
          │ Stat    │ 2.5% │ 50%  │ 97.5% │ 99%  │ Avg     │ Stdev   │ Max   │
          ├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
          │ Latency │ 0 ms │ 0 ms │ 0 ms  │ 0 ms │ 0.01 ms │ 0.11 ms │ 17 ms │
          └─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
          ┌───────────┬────────┬────────┬─────────┬─────────┬─────────┬────────┬─────────┐
          │ Stat      │ 1%     │ 2.5%   │ 50%     │ 97.5%   │ Avg     │ Stdev  │ Min     │
          ├───────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┤
          │ Req/Sec   │ 28511  │ 28511  │ 30287   │ 33407   │ 30765.1 │ 1458.2 │ 28507   │
          ├───────────┼────────┼────────┼─────────┼─────────┼─────────┼────────┼─────────┤
          │ Bytes/Sec │ 2.4 MB │ 2.4 MB │ 2.55 MB │ 2.81 MB │ 2.58 MB │ 122 kB │ 2.39 MB │
          └───────────┴────────┴────────┴─────────┴─────────┴─────────┴────────┴─────────┘

          Req/Bytes counts sampled once per second.
          # of samples: 11

          338k requests in 11.02s, 28.4 MB read
      className:
        root: talk@performance__result
  className: talk@performance
  horizontal: true
  gap: false
  defaultclassName: false

---
title: What's missing?
items:
  entries:
    - icon: link
      title: Node.js integration
      text: I just finished integrating the WebAssembly version in undici. Our beloved runtime is next.
    - icon: rocket
      title: SIMD in WebAssembly
      text: Milo matches or outperforms llhttp in native mode, but it is slower when compiled in WebAssembly.
    - icon: list-check
      title: Migrate llhttp test suite
      text: The llhttp test suite (originally from http_parser) is crucial to ensure correctness of the parser.
  horizontal: true

---
layout: quote
quote:
  sentence: |
    A person who never made a mistake
    never tried anything new.
  author: Albert Einstein

---
layout: end
# ---
